---
title: "Anomaly Detection-BD T&E"
author: Wanfei(Felicia) Luo, Aditi
output: html_notebook
---

```{r}
#Set directory
setwd("/Users/wanfeiluo/Documents/2018FALL/BD/office 365 shared/OneDrive_1_11-1-2018/OneDrive_1_1-25-2019")
getwd()
#read header entry dataset and entry comment dataset
HEdata= read.csv("Concur Data File_Header Entry Data Latest.csv")
EC =read.csv("Entry Comments.csv")
```

```{r}
library(e1071) # potential machine learning package - smv?
#####data cleaning#####
library(ggplot2) 
library(dplyr) #using dplyr to do filtering attributes and data
library(scales)
#install.packages("ggthemes") # Install 
library(ggthemes) # Load
#install.packages("randomForest")
library(randomForest)
#install.packages("stringr")
library(stringr)
#install.packages("quanteda")
library(quanteda)
#install.packages("tidytext")
library(tidytext)
library(scales)
library(tidyr)
```

```{r}
#####DATA CLEANING - SUBSET - SELECTING FEATURES######
HEdata1 <- HEdata[c(1,3,6,8,9,11,17,18,26,27,28,40)] #selecting useful features as a new subset
#names(HEdata1)
#change total report amount and expense amount from factor to numeric
HEdata1$Total.Report.Amount..rpt. <- as.numeric(as.character(HEdata1$Total.Report.Amount..rpt.))
HEdata1$Expense.Amount..rpt. <- as.numeric(as.character(HEdata1$Expense.Amount..rpt.))

HEdata1$Transaction.Date<-as.Date(HEdata1$Transaction.Date)#transcation volumn by dates

HEdata1 <- within(HEdata1, {
  Days <-weekdays(HEdata1$Transaction.Date)
})   ##add a new column in merge_data describing the date in week days
HEdata1<-na.omit(HEdata1)
HEdata1$Expense.Amount..rpt.[HEdata1$Expense.Amount..rpt. < 0] <- NA
HEdata1<-na.omit(HEdata1)
sapply(HEdata1,function(x)any(is.na(x)))

HEdata2 <- HEdata # duplicate the orginal Header Entry Dataset
#summary(HEdata1$Expense.Amount..rpt.)

#inner join HEdata_meal and EC as a new subset
merge_data<- merge(HEdata1, EC, by.x = c("Entry.Key"), by.y = c("Associated.Report.Entry.Key"))
# summary(merge_data)
# summary(merge_data$Expense.Type)

sapply(merge_data,function(x)any(is.na(x))) #checking missing data
merge_data <- merge_data[c(1,2,15,3:14)] #reorder the columns of the dataframe which is moving days column after transaction.date column)
names(merge_data)
```

```{r}
#####PLOTING OVERALL T&E####
##BY SEGMENT
outcomes <- HEdata1 %>%
  group_by(Parent.Expense.Type, Segment.Code) %>%
  summarise(total_expenses_by_group = sum(Expense.Amount..rpt.))
ggplot(outcomes, aes (x = Segment.Code, y = total_expenses_by_group, fill = Parent.Expense.Type)) +
  geom_bar(stat = 'identity', position = 'fill', colour = 'black') +
  coord_flip()+
  labs(y = 'Proportion',x = "Segment Code")+
  ggtitle("Overall T&E Expenses by Segments")
#BY WEEK DATE
outcomes_1 <- HEdata1 %>%
  group_by(Segment.Code, Days ) %>%
  summarise(total_expenses_by_days = sum(Expense.Amount..rpt.))
ggplot(outcomes_1, aes (x = Segment.Code, y = total_expenses_by_days, fill = Days)) +
  geom_bar(stat = 'identity', position = 'fill', colour = 'black') +
   scale_y_continuous(labels = scales::percent)+
  coord_flip()+
  labs(y = 'Proportion',x = "Segment Code")+
  ggtitle("Overall T&E Expenses by Days")
```
Segment 400 and 300 generated highest expenses during Weekends.
Negative Proportion means the total expenses is negative (donâ€™t know the reason) for certain Parent.Expense.Type (So only focus on Proportion 0-1.0).

```{r}

###########DATA CLEANING REGARDING MEAL $125 THRESHOLD######
# Use the expenses.amount..rpt feature to make new feature indicating below or above $125 in self-meal only
merge_data$limit_125 <- with(merge_data, 
                         ifelse(Parent.Expense.Type == 'Meals - All Food & Drink' & Expense.Amount..rpt. < 125, '0', 
                           ifelse(Parent.Expense.Type == 'Meals - All Food & Drink' & Expense.Amount..rpt. >= 125, '1', NA))) 
merge_data$limit_125 <- factor(merge_data$limit_125)
#making a subset only containing meal expenses
merge_data_selfmeal <- subset(merge_data,Expense.Type =="Meals - Self")
# summary(merge_data_selfmeal$limit_125)
# merge_data_selfmeal
meal_over <- subset(merge_data_selfmeal, limit_125 == 1)#subsetting the data which are above $125 only

```

```{r}
# #PLOTTING the Meal Expenses Outcome: above or below $125
# ggplot(merge_data_selfmeal, aes(Expense.Type,..count.. )) +
#   geom_bar(aes(fill = limit_125, position = "dodge")) +
#   labs(y = 'count', title = 'Meal Expenses Outcome -Self Meal')
# ```
# 
# ```{r}
# ##PLOTTING
# outcomes_2 <- merge_data_selfmeal %>%
#   group_by(Segment.Code, limit_125) %>%
#   summarise(num_type_1 = n())
# ggplot(outcomes_2, aes(x = Segment.Code , y = num_type_1, fill = limit_125)) +
#   geom_bar(position = 'fill', colour = 'black',stat = 'identity') +
#   scale_y_continuous(breaks= pretty_breaks())
#   labs(y = 'Proportion', title = 'Self-Meal Expenses Outcome')
```


```{r}
####Over $125 by Plant.Name###
d1 <- meal_over%>%
  # filter(limit_125 == 1)%>%
  group_by(Plant.Name)%>%
  summarise(count = length(limit_125))

d1$count <- as.numeric(d1$count)

ggplot(d1, aes(x=Plant.Name, y = count), fill = count)+
  geom_bar(stat = 'identity')+coord_flip()+
  geom_text(aes(label= count))+
  scale_fill_brewer( palette = "Blues")+
  xlab("Plant Name") + ylab("The number of ocurrence")+
  ggtitle('The Number of Ocurrence of Expenses Above $125 
          in Self-Meal 2015-2017')+
  theme_economist()

merge_data_selfmeal$limit_125 <-
  as.numeric(as.character(merge_data_selfmeal$limit_125))
merge_data_selfmeal <- merge_data_selfmeal %>%
  group_by(Plant.Name) %>% mutate(percent_125 = limit_125/sum(limit_125))

high_percent <- c(100.00,100.00,100.00,100.00,100.00,100.00,100.00,25.00,7.69,7.69,7.69,7.69,7.69,7.69,1.79,1.79,1.79,1.79,1.79)
name_1 <-c("Mansfield-BDB","CAYEY-BDD","San Diego PMG-402","SUMTER-302","Holdrege-203","Columbus (East)-202","RES TRIANGLE PK-101","OAKVILLE-302","BALTIMORE-BDD","SAN JOSE-BDB","BALTIMORE-101","BALTIMORE-301","SAN JOSE-402","FRANKLIN LAKES-SS","FRANKLIN LAKES-201","FRANKLIN LAKES-203","FRANKLIN LAKES-101","FRANKLIN LAKES-302","FRANKLIN LAKES-400")
barplot(high_percent, main = "Percentage of Self-meal over $125",
        col=c(heat.colors(19)), 
        cex.names=0.4,
        ylab = "%",
        names.arg = name_1,
        las = 2)

```

```{r}
#########PLOTTING######
# looking for outliers for each different Plant
limit_names <- c(
  '0'= "Below $125",
  '1'="Above $125")
# ggplot(meal_over,aes(Plant.Name, Total.Report.Amount..rpt.)) +
#   geom_point()+
#   coord_flip()
ggplot(merge_data_selfmeal,aes(Plant.Name, Expense.Amount..rpt.)) +
  geom_point(aes(colour = Days))+
  coord_flip()+
  facet_wrap(~limit_125,labeller =as_labeller(limit_names))+
  theme_minimal()+
  xlab("Plant Name") + ylab("T&E Expense in Each Transaction")+
  ggtitle("Expenses of Meals-self: Below $125 vs.Above $125" )
```


```{r}
###Subset HCP meal

merge_data_HCPmeal <- subset(HEdata1,Expense.Type =='HCP Meals') # still need to assign 125 limit 
merge_data_HCPmeal$Total.Report.Amount..rpt. <- as.numeric(as.character(merge_data_HCPmeal$Total.Report.Amount..rpt.))
merge_data_HCPmeal$Expense.Amount..rpt. <- as.numeric(as.character(merge_data_HCPmeal$Expense.Amount..rpt.))

merge_data_HCPmeal$limit_125 <- with(merge_data_HCPmeal, 
                         ifelse(Expense.Type == 'HCP Meals' & Expense.Amount..rpt. < 125, '0', 
                           ifelse(Expense.Type == 'HCP Meals' & Expense.Amount..rpt. >= 125, '1', NA))) 
merge_data_HCPmeal$limit_125 <- factor(merge_data_HCPmeal$limit_125)


```


```{r}
#####PLOTTING HCPMEAL#####

limit_names <- c(
  '0'= "Below $125",
  '1'="Above $125")
ggplot(merge_data_HCPmeal,aes(Plant.Name, Expense.Amount..rpt.)) +
  geom_point(aes(colour = Segment.Code))+
  coord_flip()+
  # facet_wrap(~limit_125,labeller =as_labeller(limit_names))+
  theme_minimal()+
  xlab("Plant Name") + ylab("HCP-Meal Expense in Each Transaction")+
  ggtitle("Expenses of HCP-Meal" )


ggplot(merge_data_HCPmeal,aes(Plant.Name, Expense.Amount..rpt.)) +
  geom_point(aes(colour = Days))+
  coord_flip()+
  # facet_wrap(~limit_125,labeller =as_labeller(limit_names))+
  theme_minimal()+
  xlab("Plant Name") + ylab("HCP-Meal Expense in Each Transaction")+
  ggtitle("Expenses of HCP-Meal" )


```

<!-- ##HCPmeals -->

<!-- ###Subset Entertainment -->
<!-- merge_data_enter <- subset(merge_data, Parent.Expense.Type == ' Entertainment') -->

<!-- ##Subset Other -->

<!-- model.matrix(~merge_data_selfmeal$Segment.Code) -->


```{r}
# ######Modeling#########
# ###Split Dataset#####
# HEdata1 <- HEdata[c(1,3,6,8,9,11,17,18,26,27,28,40)]
# full<-merge_data_selfmeal[c(6,8,10,11,12,15)]
# 
# train <- full[1:18000, ]
# test <- full[18001:nrow(full), ]
# 
# set.seed(651)
# ###Model-Random Forest#####
# rf_mod <- randomForest(limit_125 ~ Segment.Code+Plant.Code+Parent.Expense.Type+Expense.Amount..rpt.,
#                        data = train,
#                        ntree = 10,
#                        importance =TRUE)
# 
# plot(rf_mod, ylim=c(0,1))
# legend('topright', colnames(rf_mod$err.rate), col=1:6, fill=1:6)
```

```{r}
###Keywords Mining####
Key_BD =read.csv("BD Keywords.csv")
#summary(Key_BD$Keywords)
EC[]<-lapply(EC,as.character)
head(EC)
gift_found <- dplyr::filter(EC, grepl('gift card|giftcard', Comment))
gift_found_full<- merge(HEdata1, gift_found, by.x = c("Entry.Key"), by.y = c("Associated.Report.Entry.Key"))

hcp_found <- dplyr::filter(EC, grepl('hcp|HCP|HCO|hco', Comment))
hcp_found_full<- merge(HEdata1, hcp_found, by.x = c("Entry.Key"), by.y = c("Associated.Report.Entry.Key"))

spa_found <- dplyr::filter(EC, grepl(" SPA ", Comment, ignore.case = FALSE))
spa_found_full<- merge(HEdata1, spa_found, by.x = c("Entry.Key"), by.y = c("Associated.Report.Entry.Key"))

```

```{r}
######PLOTING by keywords Comment using tidytext packages######
text_merge <-data_frame(line = 1:88508, text = merge_data$Comment)
text_merge$text <- as.character(text_merge$text)

tidy_text_merge <- text_merge %>%
  unnest_tokens(word, text)

data(stop_words)
tidy_text_merge<- tidy_text_merge%>%
  anti_join(stop_words)

tidy_text_merge %>%
  count(word, sort = TRUE)

text_over <-data_frame(line = 1:93, text = meal_over$Comment)
text_over$text <- as.character(text_over$text)

tidy_text_over <- text_over %>%
  unnest_tokens(word, text)

data(stop_words)
tidy_text_over<- tidy_text_over%>%
  anti_join(stop_words)

tidy_text_over %>%
  count(word, sort = TRUE)

text_keywords <-data_frame(line = 1:82, text = Key_BD$To_Display)
text_keywords$text<-as.character(text_keywords$text)

tidy_text_keywords <- text_keywords%>%
  unnest_tokens(word,text)

tidy_text_keywords<- tidy_text_keywords%>%
  anti_join(stop_words)
 
tidy_text_keywords%>%
  count(word,sort = TRUE)

frequency_a <- bind_rows(mutate(tidy_text_merge, author = "original data"),
                       mutate(tidy_text_over, author = "self-meal_over $125"),
                       mutate(tidy_text_keywords,author = "keywords"))%>%
  mutate(word = str_extract(word, "[a-z']+"))%>%
  count(author, word)%>%
  mutate(proportion = n / sum (n))%>%
  select(-n)%>%
  spread(author,proportion)%>%
  gather(author,proportion, 'original data':'self-meal_over $125')



ggplot(frequency_a, aes(x = proportion, y = keywords))+
  geom_abline(color = "gray40", lty = 2)+
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3)+
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5)+
  scale_x_log10(labels = percent_format())+
  scale_y_log10(labels = percent_format())+
  scale_color_gradient(limits = c(0,0.001), low = "blue", high = "#5011D1")+
  facet_wrap(~author, ncol = 2)+
  theme(legend.position = "none")+
  labs(y = "Keywords", x = NULL)

```



```{r}
text_merge <-data_frame(line = 1:21524, text = merge_data_selfmeal$Comment)
text_merge$text <- as.character(text_merge$text)

tidy_text_merge <- text_merge %>%
  unnest_tokens(word, text)

data(stop_words)
tidy_text_merge<- tidy_text_merge%>%
  anti_join(stop_words)

tidy_text_merge %>%
  count(word, sort = TRUE)

text_over <-data_frame(line = 1:93, text = meal_over$Comment)
text_over$text <- as.character(text_over$text)

tidy_text_over <- text_over %>%
  unnest_tokens(word, text)

data(stop_words)
tidy_text_over<- tidy_text_over%>%
  anti_join(stop_words)

tidy_text_over %>%
  count(word, sort = TRUE)

text_keywords <-data_frame(line = 1:82, text = Key_BD$To_Display)
text_keywords$text<-as.character(text_keywords$text)

tidy_text_keywords <- text_keywords%>%
  unnest_tokens(word,text)

tidy_text_keywords<- tidy_text_keywords%>%
  anti_join(stop_words)
 
tidy_text_keywords%>%
  count(word,sort = TRUE)

frequency_a <- bind_rows(mutate(tidy_text_merge, meal_type = "self-meal"),
                       mutate(tidy_text_over, meal_type = "self-meal_over $125"),
                       mutate(tidy_text_keywords,meal_type = "keywords"))%>%
  mutate(word = str_extract(word, "[a-z']+"))%>%
  count(meal_type, word)%>%
  mutate(proportion = n / sum (n))%>%
  select(-n)%>%
  spread(meal_type,proportion)%>%
  gather(meal_type,proportion, 'self-meal':'self-meal_over $125')



ggplot(frequency_a, aes(x = proportion, y = keywords))+
  geom_abline(color = "gray40", lty = 2)+
  geom_jitter(alpha = 0.15, size = 2.5, width = 0.7, height = 0.3)+
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 0.5)+
  scale_x_log10(labels = percent_format())+
  scale_y_log10(labels = percent_format())+
  scale_color_gradient(limits = c(0,0.001), low = "blue", high = "#5011D1")+
  facet_wrap(~meal_type, ncol = 2)+
  theme(legend.position = "none")+
  labs(y = "Keywords", x = NULL)
```

```{r}
frequency_b <- bind_rows(mutate(tidy_text_merge, meal_type = "self_meal"),
                       mutate(tidy_text_over, meal_type = "self_meal_over_125"))%>%
  mutate(word = str_extract(word, "[a-z']+"))%>%
  count(meal_type, word)%>%
  mutate(proportion = n / sum (n))%>%
  select(-n)%>%
  spread(meal_type,proportion)%>%
  gather(meal_type,proportion, 'self_meal':'self_meal_over_125')

frequency_b<- frequency_b %>%
  select(meal_type, word, proportion) %>%
  spread(meal_type, proportion)%>%
  arrange(self_meal,self_meal_over_125)

ggplot(frequency_b,aes(self_meal, self_meal_over_125))+
  geom_jitter(alpha = 0.15, size = 2.5, width = 0.5, height = 1)+
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 0)+
  scale_x_log10(labels = percent_format())+
  scale_y_log10(labels = percent_format())+
  scale_color_gradient(limits = c(0,0.1), low = "red", high = "#5011D1")+
  geom_abline(color = "red")

```






